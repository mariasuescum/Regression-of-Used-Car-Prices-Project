# Problema de RegresiÃ³n - Poryecto V para FactoriaF5

### Realizado por el equipo 6:
#### [Anca Bacria](https://github.com/a-bac-0)
#### [AndreÃ­na Suescum](https://github.com/mariasuescum)
#### [Alla Haruntyunyan](https://github.com/alharuty)
#### [Mariela Adimari](https://github.com/marie-adi)
#### [CÃ©sar Mercado](https://github.com/merkandez)

Este proyecto tiene como objetivo construir un modelo de machine learning capaz de predecir el precio de venta de un vehÃ­culo en base a caracterÃ­sticas como su antigÃ¼edad, kilometraje, potencia del motor, tipo de combustible, marca, modelo. Utiliza un enfoque de regresiÃ³n con Random Forest y se ha optimizado mediante bÃºsqueda aleatoria de hiperparÃ¡metros y validaciÃ³n cruzada.
Decidimos utilizar el [dataset](https://www.kaggle.com/competitions/playground-series-s4e9) ya sea para uso particular o profesional, el usuario podrÃ¡ adivinar el precio de venta de coches de segundamano. 

PodrÃ¡s descargar el repositorio:
```bash
git clone https://github.com/Factoria-F5-dev/ai-project-Regression.git
```

Crear y activar el entorno virtual en Mac:
```bash
python -m venv .venv
source .venv/bin/activate
```

Crear y activar el entorno virtual en Linux o Windows:
```bash
python -m venv .venv
venv\Scripts\activate
```

Instalar las dependencias necesarias:
```bash
pip install -r requirements.txt
```

Probar el modelo:
```bash
python tunning_model.py
```

## ğŸ“‚ Estructura del Proyecto

```text
.
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ brand_enumeration.csv              # CodificaciÃ³n de marcas
â”‚   â”œâ”€â”€ cleaned_dataset.csv                # Dataset limpio v1
â”‚   â”œâ”€â”€ final_dataset.csv                  # Dataset limpio final
â”‚   â”œâ”€â”€ used_cars.csv                      # Dataset original
â”‚   â”œâ”€â”€ fuel_type_enumeration.csv          # CodificaciÃ³n tipo de combustible
â”‚   â”œâ”€â”€ model_enumeration.csv              # CodificaciÃ³n de modelos
â”‚   â””â”€â”€ transmission_enumeration.csv       # CodificaciÃ³n de transmisiÃ³n
â”œâ”€â”€ models/
â”‚   â””â”€â”€ random_forest_best.pkl             # Modelo entrenado con mejores hiperparÃ¡metros
â”œâ”€â”€ used_cars.ipynb                        # Notebook de exploraciÃ³n, visualizaciÃ³n y anÃ¡lisis de datos
â”œâ”€â”€ model.py                               # Script base de entrenamiento
â”œâ”€â”€ tunning_model.py                       # Script final con ajuste de hiperparÃ¡metros, K-Fold y evaluaciÃ³n
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt                       # Dependencias del proyecto
```

## ğŸ§¾ Dataset
El conjunto de datos final contiene 4,000 registros y 9 columnas, todas numÃ©ricas y las categrÃ³ricas convertidas a valores numÃ©ricos mediante **LabelEncoder**. Las columnas utilizadas como caracterÃ­sticas (features) son:

- age: antigÃ¼edad del vehÃ­culo en aÃ±os
- milage: kilometraje acumulado
- accident: accidente reportado o no
- engine_hp: potencia del motor en HP
- brand_id: marca del vehÃ­culo (codificado)
- model_id: modelo del vehÃ­culo (codificado)
- fuel_type_id: tipo de combustible (codificado)
- transmission_norm: tipo de transmisiÃ³n (codificado) (AutomÃ¡tico, Manual, Otros)

**Variable objetivo (target):**

- price: Precio de venta del vehÃ­culo en â‚¬.

## âš™ï¸ Modelado
El modelo principal utilizado fue un **Random Forest Regressor**, optimizado mediante **RandomizedSearchCV**. Se evaluaron varios hiperparÃ¡metros:

- n_estimators
- max_depth
- min_samples_split
- min_samples_leaf

AdemÃ¡s, se aplicÃ³ **validaciÃ³n cruzada K-Fold** (5 folds) para medir estabilidad y capacidad de generalizaciÃ³n.

## ğŸ“ˆ Resultados
- RÂ² en conjunto de prueba: ~0.8114
- MSE en test: Aproximadamente 165488040
- Overfitting <5%: 0.0382
- RÂ² promedio (K-Fold): 0.8040
- DesviaciÃ³n estÃ¡ndar K-Fold: 0.0270

El modelo generaliza bien y no muestra signos de sobreajuste ya que hemos ajustando la **profundidad de los Ã¡rboles.**

![MÃ©tricas del modelo](images/mÃ©tricas_modelo.png)

## Principales librerÃ­as a usar:
- pandas
- numpy
- scikit-learn
- scipy
- joblib


## Interfaz grÃ¡fica con Gradio para uso personal o profesional
[Link]()

Es una interfaz fÃ¡cil e intuitiva.

![Interfaz grÃ¡fica con Gradio](images/interfaz.png)

Para ponerlo en marcha:
```bash
python gradio_app/main.py
```

Y en tu navegador ingresa:
```bash
http://127.0.0.1:7860
```
Y ya puedes utilizar el Tasador de coches de segundamano.

## ğŸ§¾ Test unitarios

Para garantizar la calidad y fiabilidad del modelo y el preprocesamiento de datos, hemos implementado pruebas unitarias utilizando la librerÃ­a `unittest` de Python. Creamos 5 diferentes test para verificar que:
- Se pasan las variables (caracterÃ­sticas) necesarios: age, milage, accident, engine_hp, brand_id, model_id, fuel_type_id, transmission_norm
- Existe la columna â€˜priceâ€™
- La mÃ©trica RÂ² es mayor que 0.70 y el modelo funciona de forma eficiente
- MSE sea menor que 170000000
- El modelo se guarda correctamente en la carpeta models

Â¿CÃ³mo ejecutar las pruebas?

Ejecuta el script:
```bash
python -m unittest tests/model_tests.py
```

Esto ejecutarÃ¡ todas las pruebas unitarias definidas en el archivo `model_tests.py`.

**Â¿QuÃ© pruebas se incluyen?**

- **Test de Preprocesamiento:** Verifica que los datos se carguen correctamente y se procesen sin errores.
- **Test de MÃ©tricas:** Asegura que las mÃ©tricas como el **MSE** y el **RÂ²** cumplan con los valores mÃ­nimos establecidos para garantizar que el modelo tenga un rendimiento aceptable.

**Â¿Por quÃ© utilizar Unit Tests?**

Con estos tests podemos detectar errores en el proyecto y asegurar que los componentes del proyecto sigan funcionando correctamente cuando se realicen cambios o mejoras. 

Esto es especialmente Ãºtil en proyectos de Machine Learning, donde el preprocesamiento, la selecciÃ³n de caracterÃ­sticas y el modelo pueden verse afectados por cambios en los datos o en el cÃ³digo.

## ğŸ‘¥ Trabajo en equipo

Para optimizar el rendimiento del equipo, adoptamos el modelo de trabajo Gitflow junto con GitHub y ramas de trabajo en local y remoto, y aplicamos la metodologÃ­a Scrum. Desde el inicio del proyecto, definimos fechas lÃ­mite claras para cada tarea asignada a los miembros del equipo. 

Durante el desarrollo, ajustamos dichas fechas segÃºn fuera necesario, manteniendo siempre el enfoque en la entrega de resultados dentro de los plazos establecidos.